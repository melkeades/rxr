{
    "sourceFile": "src/Dome-1029-preVidMem.jsx",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 4,
            "patches": [
                {
                    "date": 1698610124178,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1698610400117,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -35,8 +35,12 @@\n       //  hls.attachMedia(videoElement)\r\n       //  hls.on(Hls.Events.MANIFEST_PARSED, () => {\r\n       //    videoElement.play()\r\n       //  })\r\n+             const videoProps = {crossOrigin = 'Anonymous',\r\n+loop = true,\r\n+muted = false,\r\n+volume = 0.5}\r\n       const _videoElement = document.createElement('video')\r\n       _videoElement.crossOrigin = 'Anonymous'\r\n       _videoElement.loop = true\r\n       _videoElement.muted = false\r\n"
                },
                {
                    "date": 1698610412150,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -35,12 +35,12 @@\n       //  hls.attachMedia(videoElement)\r\n       //  hls.on(Hls.Events.MANIFEST_PARSED, () => {\r\n       //    videoElement.play()\r\n       //  })\r\n-             const videoProps = {crossOrigin = 'Anonymous',\r\n-loop = true,\r\n-muted = false,\r\n-volume = 0.5}\r\n+             const videoProps = {crossOrigin : 'Anonymous',\r\n+loop : true,\r\n+muted : false,\r\n+volume : 0.5}\r\n       const _videoElement = document.createElement('video')\r\n       _videoElement.crossOrigin = 'Anonymous'\r\n       _videoElement.loop = true\r\n       _videoElement.muted = false\r\n"
                },
                {
                    "date": 1698610505595,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -36,23 +36,25 @@\n       //  hls.on(Hls.Events.MANIFEST_PARSED, () => {\r\n       //    videoElement.play()\r\n       //  })\r\n       const videoProps = { crossOrigin: 'Anonymous', loop: true, muted: false, volume: 0.5 }\r\n-      const _videoElement = document.createElement('video')\r\n-      _videoElement.crossOrigin = 'Anonymous'\r\n-      _videoElement.loop = true\r\n-      _videoElement.muted = false\r\n-      _videoElement.volume = 0.5\r\n-      _videoElement.src = file\r\n-      _videoElement.load()\r\n-      if (!videoPaused) {\r\n-        // _videoElement.play()\r\n-      } else {\r\n-        pause$.style.opacity = 1\r\n-        setVideoPaused(!videoPaused)\r\n-      }\r\n-      _videoElement.play()\r\n-      _texture = new THREE.VideoTexture(_videoElement)\r\n+    //   const _videoElement = document.createElement('video')\r\n+    //   _videoElement.crossOrigin = 'Anonymous'\r\n+    //   _videoElement.loop = true\r\n+    //   _videoElement.muted = false\r\n+    //   _videoElement.volume = 0.5\r\n+    //   _videoElement.src = file\r\n+    //   _videoElement.load()\r\n+\r\n+    //   if (!videoPaused) {\r\n+    //     // _videoElement.play()\r\n+    //   } else {\r\n+    //     pause$.style.opacity = 1\r\n+    //     setVideoPaused(!videoPaused)\r\n+    //   }\r\n+    //   _videoElement.play()\r\n+    //   _texture = new THREE.VideoTexture(_videoElement)\r\n+              _texture = useVideoTexture(file, videoProps)\r\n       videoElement.current = _videoElement\r\n       // console.log('video')\r\n     } else if (_mediaType === 'image') {\r\n       _texture = new THREE.TextureLoader().load(file)\r\n"
                },
                {
                    "date": 1698610703462,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -52,10 +52,10 @@\n       //     setVideoPaused(!videoPaused)\r\n       //   }\r\n       //   _videoElement.play()\r\n       //   _texture = new THREE.VideoTexture(_videoElement)\r\n-      _texture = useVideoTexture(file, videoProps)\r\n-      videoElement.current = _videoElement\r\n+    //   _texture = useVideoTexture(file, videoProps)\r\n+    //   videoElement.current = _videoElement\r\n       // console.log('video')\r\n     } else if (_mediaType === 'image') {\r\n       _texture = new THREE.TextureLoader().load(file)\r\n       // console.log('image')\r\n"
                }
            ],
            "date": 1698610124178,
            "name": "Commit-0",
            "content": "import { useCallback } from 'react'\r\nimport { useRef } from 'react'\r\nimport { useState, useEffect } from 'react'\r\nimport { useThree } from '@react-three/fiber'\r\n// import Hls from 'hls.js'\r\nimport * as THREE from 'three'\r\nimport { useVideoTexture } from '@react-three/drei'\r\n\r\nexport default function Dome({ photoIndex, setPhotoIndex, mediaPath, mediaDb }) {\r\n  const { gl } = useThree()\r\n  const videoElement = useRef()\r\n  const [texture, setTexture] = useState()\r\n  const [videoPaused, setVideoPaused] = useState(false)\r\n  const [videoMuted, setVideoMuted] = useState(true)\r\n  const [mediaType, setMediaType] = useState()\r\n  const initDone = useRef(false)\r\n\r\n  const sel = (e) => document.querySelector(e)\r\n  const pause$ = sel('.btn--pause')\r\n  const vol$ = sel('.btn--vol')\r\n  let _texture = {}\r\n  // const v = useVideoTexture('/360/w5.mp4')\r\n  // const _vd = document.createElement('video')\r\n  // _vd.src = '/360/w5.mp4'\r\n  // _vd.muted = true\r\n  // const vd = new THREE.VideoTexture(_vd)\r\n  // console.log(v, vd)\r\n  useEffect(() => {\r\n    console.log('index: ' + photoIndex)\r\n    // let _texture = {}\r\n    const _mediaType = mediaDb[photoIndex].type\r\n    const file = mediaPath + mediaDb[photoIndex].src\r\n    if (_mediaType === 'video') {\r\n      //  hls.loadSource(file)\r\n      //  hls.attachMedia(videoElement)\r\n      //  hls.on(Hls.Events.MANIFEST_PARSED, () => {\r\n      //    videoElement.play()\r\n      //  })\r\n      const _videoElement = document.createElement('video')\r\n      _videoElement.crossOrigin = 'Anonymous'\r\n      _videoElement.loop = true\r\n      _videoElement.muted = false\r\n      _videoElement.volume = 0.5\r\n      _videoElement.src = file\r\n      _videoElement.load()\r\n      if (!videoPaused) {\r\n        // _videoElement.play()\r\n      } else {\r\n        pause$.style.opacity = 1\r\n        setVideoPaused(!videoPaused)\r\n      }\r\n      _videoElement.play()\r\n      _texture = new THREE.VideoTexture(_videoElement)\r\n      videoElement.current = _videoElement\r\n      // console.log('video')\r\n    } else if (_mediaType === 'image') {\r\n      _texture = new THREE.TextureLoader().load(file)\r\n      // console.log('image')\r\n    }\r\n    _texture.mapping = THREE.EquirectangularReflectionMapping\r\n    _texture.colorSpace = THREE.SRGBColorSpace\r\n    _texture.minFilter = _texture.magFilter = THREE.LinearFilter\r\n    setTexture(_texture)\r\n    setMediaType(_mediaType)\r\n    return () => {\r\n      // gl.renderLists.dispose()\r\n      if (mediaType === 'video') {\r\n        videoElement.current?.pause()\r\n        videoElement.current?.remove()\r\n        // videoElement.src = ''\r\n        // videoElement.load()\r\n        // videoElement.remove()\r\n        console.log('remove')\r\n        // _texture.dispose()\r\n      }\r\n      // if (initDone.current)\r\n      // else initDone.current = true\r\n    }\r\n  }, [photoIndex, mediaType])\r\n\r\n  // useEffect(() => {\r\n  //   return function () {\r\n  //     videoElement.current?.pause()\r\n  //     videoElement.current?.remove()\r\n  //   }\r\n  // }, [photoIndex])\r\n\r\n  useEffect(() => {\r\n    function handler() {\r\n      console.log('handler')\r\n      if (mediaType === 'video') {\r\n        console.log('is video')\r\n        if (videoPaused) {\r\n          pause$.style.opacity = 1\r\n          videoElement.current.play()\r\n          // console.log('pl', videoElement.play)\r\n        } else {\r\n          pause$.style.opacity = 0.3\r\n          // console.log('pa')\r\n          videoElement.current.pause()\r\n        }\r\n        setVideoPaused(!videoPaused)\r\n      }\r\n    }\r\n    pause$.addEventListener('click', handler)\r\n    return () => pause$.removeEventListener('click', handler)\r\n  }, [videoPaused, videoElement, mediaType])\r\n\r\n  useEffect(() => {\r\n    function handler() {\r\n      vol$.style.opacity = videoMuted ? 1 : 0.3\r\n      setVideoMuted(!videoMuted)\r\n      console.log('mm')\r\n    }\r\n    vol$.addEventListener('click', handler)\r\n    return () => vol$.removeEventListener('click', handler)\r\n  }, [videoMuted])\r\n\r\n  return (\r\n    <>\r\n      <mesh position={[0, 0, 0]} scale-x={-1}>\r\n        <sphereGeometry attach=\"geometry\" args={[100, 100, 100]} />\r\n        <meshBasicMaterial attach=\"material\" toneMapped={false} map={texture} side={THREE.BackSide} onUpdate={(self) => (self.needsUpdate = true)} />\r\n      </mesh>\r\n    </>\r\n  )\r\n}\r\n"
        }
    ]
}